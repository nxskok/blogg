<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>Ken's Blog</title>
    <link>http://ritsokiguess.site/blogg/</link>
    <atom:link href="http://ritsokiguess.site/blogg/index.xml" rel="self" type="application/rss+xml"/>
    <description>Ken's Blog
</description>
    <generator>Distill</generator>
    <lastBuildDate>Mon, 09 May 2022 00:00:00 +0000</lastBuildDate>
    <item>
      <title>Random sampling from groups</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2022-05-09-random-sampling-from-groups</link>
      <description>


&lt;h1 id="packages"&gt;Packages&lt;/h1&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In a previous post, I discussed how we might sample in groups, where each group was a sample from a different population. I introduced this function:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;gen_sample &amp;lt;- function(n, mean, sd) {
  tibble(gp = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), n = n, mean = mean, sd = sd) %&amp;gt;% 
    rowwise() %&amp;gt;% 
    mutate(z = list(rnorm(n, mean, sd))) %&amp;gt;% 
    unnest(z) %&amp;gt;% 
    select(gp, z)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;that samples from normal populations with possibly different means, SDs, and sample sizes in different groups.&lt;/p&gt;
&lt;h1 id="explanation"&gt;Explanation&lt;/h1&gt;
&lt;p&gt;This is (more or less) the same explanation that appeared at the end of the previous post, so feel free to skip if you have read it before.&lt;/p&gt;
&lt;p&gt;The first step is to make a data frame with one row for each sample that will be generated. This uses the inputs to the function above, so we will make some up:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;n &amp;lt;- c(5, 3)
mean &amp;lt;- c(20, 10)
sd &amp;lt;- c(2, 1)
tibble(gp = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), n = n, mean = mean, sd = sd) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 4
  gp        n  mean    sd
  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
1 x         5    20     2
2 y         3    10     1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Evidently, in a function for public consumption, you would check that all the inputs are the same length, or you would rely on &lt;code&gt;tibble&lt;/code&gt; telling you that only vectors of length 1 are recycled.&lt;a href="#fn1" class="footnote-ref" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The groups are for no good reason called &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The next two lines generate random samples, one for each group, according to the specifications, and store them each in one cell of the two-row spreadsheet:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;  tibble(gp = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), n = n, mean = mean, sd = sd) %&amp;gt;% 
    rowwise() %&amp;gt;% 
    mutate(z = list(rnorm(n, mean, sd))) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 5
# Rowwise: 
  gp        n  mean    sd z        
  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt;   
1 x         5    20     2 &amp;lt;dbl [5]&amp;gt;
2 y         3    10     1 &amp;lt;dbl [3]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new column &lt;code&gt;z&lt;/code&gt; is a list column, since the top cell of the column is a vector of length 5, and the bottom cell is a vector of length 3. To actually see the values they contain, we &lt;code&gt;unnest&lt;/code&gt; &lt;code&gt;z&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;  tibble(gp = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), n = n, mean = mean, sd = sd) %&amp;gt;% 
    rowwise() %&amp;gt;% 
    mutate(z = list(rnorm(n, mean, sd))) %&amp;gt;% 
    unnest(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 8 × 5
  gp        n  mean    sd     z
  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
1 x         5    20     2 20.2 
2 x         5    20     2 19.7 
3 x         5    20     2 15.4 
4 x         5    20     2 17.6 
5 x         5    20     2 19.4 
6 y         3    10     1 11.8 
7 y         3    10     1  9.93
8 y         3    10     1 10.8 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and, finally, the middle three columns were only used to generate the values in &lt;code&gt;z&lt;/code&gt;, so they can be thrown away now by &lt;code&gt;select&lt;/code&gt;ing only &lt;code&gt;gp&lt;/code&gt; and &lt;code&gt;z&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;rowwise&lt;/code&gt; is necessary:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;  tibble(gp = c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;), n = n, mean = mean, sd = sd) %&amp;gt;% 
    mutate(z = list(rnorm(n, mean, sd))) %&amp;gt;% 
    unnest(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 4 × 5
  gp        n  mean    sd     z
  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
1 x         5    20     2 17.2 
2 x         5    20     2  9.53
3 y         3    10     1 17.2 
4 y         3    10     1  9.53&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;because &lt;code&gt;rnorm&lt;/code&gt; is vectorized, and for the &lt;code&gt;x&lt;/code&gt; sample, R will draw one sampled value from each normal distribution, and then repeat the same values for the &lt;code&gt;y&lt;/code&gt; sample. This is very much &lt;em&gt;not&lt;/em&gt; what we want.&lt;/p&gt;
&lt;p&gt;I used the same idea to draw my random chi-squared data later on:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(df = c(2,6)) %&amp;gt;% 
  rowwise() %&amp;gt;% 
  mutate(z = list(rchisq(20, df))) %&amp;gt;% 
  unnest(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 40 × 2
      df     z
   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
 1     2 2.54 
 2     2 4.00 
 3     2 0.410
 4     2 0.821
 5     2 2.44 
 6     2 1.67 
 7     2 2.24 
 8     2 2.51 
 9     2 1.52 
10     2 0.511
# … with 30 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(twenty values from &lt;span class="math inline"&gt;\(\chi^2_2\)&lt;/span&gt;, followed by twenty from &lt;span class="math inline"&gt;\(\chi^2_6\)&lt;/span&gt;.)&lt;/p&gt;
&lt;p&gt;This suggests that I ought to be able to generalize my function &lt;code&gt;gen_sample&lt;/code&gt;. Generalizing to any number of groups needs no extra work: the length of the input &lt;code&gt;n&lt;/code&gt; determines the number of groups, and the values in &lt;code&gt;n&lt;/code&gt; determine the size of each of those groups.&lt;/p&gt;
&lt;p&gt;The interesting generalization is the distribution to sample from. The first parameter of the functions &lt;code&gt;rnorm&lt;/code&gt;, &lt;code&gt;rchisq&lt;/code&gt; etc. is always the number of random values to generate, but the remaining parameters are different for each distribution. This suggests that my generalized random sample generator ought to have the name of the random sampling function as input, followed by &lt;code&gt;...&lt;/code&gt; to allow any other inputs needed by that sampling function; these then get passed on.&lt;/p&gt;
&lt;h1 id="generalizing"&gt;Generalizing&lt;/h1&gt;
&lt;p&gt;To generalize &lt;code&gt;gen_sample&lt;/code&gt; to a new function &lt;code&gt;sample_groups&lt;/code&gt;, we need to consider how to handle different distributions. The distribution itself is not the hard part; that can be specified by having the random sample generator function for the desired distribution as an input to the new function. The problem is that each distribution has different parameters, which need to be inputs to &lt;code&gt;sample_groups&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The standard way of doing this kind of thing is to use the &lt;code&gt;...&lt;/code&gt; input to a function. If I had just one group, it would go like this:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sample_group &amp;lt;- function(n, dist, ...) {
  dist(n, ...)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sample_group(5, rnorm, mean = 10, sd = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1]  9.635103 12.759099  9.783343  8.854937 15.835440&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sample_group(6, rpois, lambda = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 1 1 2 3 2 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The additional (named) inputs to &lt;code&gt;sample_group&lt;/code&gt; are passed on unchanged to the random sample generator, to generate respectively normal random values with mean 10 and SD 3, and Poisson random values with mean 3.&lt;a href="#fn2" class="footnote-ref" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The random sample generators are vectorized, but the obvious thing for generating two samples from different distributions does not work:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sample_group(c(6, 3), rnorm, mean = c(10, 20), sd = c(3, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1]  8.968853 18.881153&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We appear to have one value from each distribution, not six from the first and three from the second. This, I &lt;em&gt;think&lt;/em&gt;, is what the help files say will happen.&lt;/p&gt;
&lt;p&gt;Even if I can get this to work, it might be that I want to generate samples from different distributions. So, onto idea #2.&lt;/p&gt;
&lt;p&gt;Let’s suppose I ask the user to write the code to generate each sample as text (a vector of pieces of text, one for each sample). Here’s how my example above would look:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;code &amp;lt;- c(&amp;quot;rnorm(5, mean = 10, sd = 3)&amp;quot;, 
          &amp;quot;rpois(6, lambda = 2)&amp;quot;)
code&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;rnorm(5, mean = 10, sd = 3)&amp;quot; &amp;quot;rpois(6, lambda = 2)&amp;quot;       &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem is that this is text, not runnable code. One way to turn this into something useful is to &lt;code&gt;parse&lt;/code&gt; it:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;pc &amp;lt;- parse(text = code[1])
pc&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;expression(rnorm(5, mean = 10, sd = 3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This has turned the text into an &lt;code&gt;expression&lt;/code&gt;, something that can be evaluated, thus:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;eval(pc)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1]  7.723985  8.010932  8.809642 12.769762 11.501459&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So now we have a strategy, or so you would think:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(code) %&amp;gt;% 
  rowwise() %&amp;gt;% 
  mutate(expr = list(parse(text = code))) %&amp;gt;%
  pull(expr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[[1]]
expression(rnorm(5, mean = 10, sd = 3))

[[2]]
expression(rpois(6, lambda = 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem is that both things in &lt;code&gt;code&lt;/code&gt; go into both &lt;code&gt;expression&lt;/code&gt;s, even with &lt;code&gt;rowwise&lt;/code&gt;. So this won’t work.&lt;/p&gt;
&lt;p&gt;The usual thing to try next is &lt;code&gt;map&lt;/code&gt; instead of &lt;code&gt;rowwise&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(code) %&amp;gt;% 
  mutate(expr = map(code, ~parse(text = .))) %&amp;gt;% 
  mutate(z = map(expr, ~eval(.))) %&amp;gt;% 
  unnest(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 11 × 3
   code                        expr             z
   &amp;lt;chr&amp;gt;                       &amp;lt;list&amp;gt;       &amp;lt;dbl&amp;gt;
 1 rnorm(5, mean = 10, sd = 3) &amp;lt;expression&amp;gt; 13.3 
 2 rnorm(5, mean = 10, sd = 3) &amp;lt;expression&amp;gt;  4.78
 3 rnorm(5, mean = 10, sd = 3) &amp;lt;expression&amp;gt; 11.2 
 4 rnorm(5, mean = 10, sd = 3) &amp;lt;expression&amp;gt;  9.96
 5 rnorm(5, mean = 10, sd = 3) &amp;lt;expression&amp;gt; 11.5 
 6 rpois(6, lambda = 2)        &amp;lt;expression&amp;gt;  1   
 7 rpois(6, lambda = 2)        &amp;lt;expression&amp;gt;  4   
 8 rpois(6, lambda = 2)        &amp;lt;expression&amp;gt;  3   
 9 rpois(6, lambda = 2)        &amp;lt;expression&amp;gt;  2   
10 rpois(6, lambda = 2)        &amp;lt;expression&amp;gt;  2   
11 rpois(6, lambda = 2)        &amp;lt;expression&amp;gt;  4   &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That seems to have worked.&lt;/p&gt;
&lt;p&gt;So now we have the ingredients for a version of &lt;code&gt;sample_groups&lt;/code&gt; based on the user writing the random-sampling code for us:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sample_groups &amp;lt;- function(code) {
  tibble(code) %&amp;gt;% 
    mutate(expr = map(code, ~parse(text = .))) %&amp;gt;% 
    mutate(z = map(expr, ~eval(.))) %&amp;gt;% 
    unnest(z) %&amp;gt;% 
    select(-expr)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and to test:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;d &amp;lt;- sample_groups(code)
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 11 × 2
   code                            z
   &amp;lt;chr&amp;gt;                       &amp;lt;dbl&amp;gt;
 1 rnorm(5, mean = 10, sd = 3) 16.4 
 2 rnorm(5, mean = 10, sd = 3) 11.1 
 3 rnorm(5, mean = 10, sd = 3)  2.95
 4 rnorm(5, mean = 10, sd = 3)  6.55
 5 rnorm(5, mean = 10, sd = 3)  9.54
 6 rpois(6, lambda = 2)         2   
 7 rpois(6, lambda = 2)         1   
 8 rpois(6, lambda = 2)         1   
 9 rpois(6, lambda = 2)         3   
10 rpois(6, lambda = 2)         0   
11 rpois(6, lambda = 2)         1   &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then something like&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t.test(z ~ code, data = d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Welch Two Sample t-test

data:  z by code
t = 3.4828, df = 4.2827, p-value = 0.02264
alternative hypothesis: true difference in means is not equal to 0
95 percent confidence interval:
  1.775809 14.141248
sample estimates:
mean in group rnorm(5, mean = 10, sd = 3) 
                                 9.291862 
       mean in group rpois(6, lambda = 2) 
                                 1.333333 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is a little bit clumsy, but so it is.&lt;/p&gt;
&lt;p&gt;Using the &lt;code&gt;eval(parse(text = something))&lt;/code&gt; idea is not (apparently) very well regarded. One immediate problem is that the user could put any code at all (that evaluates into a vector of numbers) into the input &lt;code&gt;code&lt;/code&gt;, which seems less than secure:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;code &amp;lt;- c(&amp;quot;1:3&amp;quot;, &amp;quot;mtcars$mpg&amp;quot;)
sample_groups(code)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 35 × 2
   code           z
   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt;
 1 1:3          1  
 2 1:3          2  
 3 1:3          3  
 4 mtcars$mpg  21  
 5 mtcars$mpg  21  
 6 mtcars$mpg  22.8
 7 mtcars$mpg  21.4
 8 mtcars$mpg  18.7
 9 mtcars$mpg  18.1
10 mtcars$mpg  14.3
# … with 25 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I want to get back to the user inputting the desired random sample generators as functions, and then running those functions on the rest of the input:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;n &amp;lt;- c(6, 3)
dist &amp;lt;- c(rnorm, rpois)
mean &amp;lt;- c(10, NA)
sd &amp;lt;- c(3, NA)
lambda &amp;lt;- c(NA, 2)
gp &amp;lt;- c(&amp;quot;x&amp;quot;, &amp;quot;y&amp;quot;)
d &amp;lt;- tibble(n = n, dist = dist, mean = mean, sd = sd, lambda = lambda, gp = gp)
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 6
      n dist    mean    sd lambda gp   
  &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
1     6 &amp;lt;fn&amp;gt;      10     3     NA x    
2     3 &amp;lt;fn&amp;gt;      NA    NA      2 y    &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, how to run those functions in &lt;code&gt;dist&lt;/code&gt;, with the parameters shown? This is what &lt;code&gt;do.call&lt;/code&gt; does:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;do.call(rnorm, list(n = 5, mean = 10, sd = 3))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1]  5.467376 10.075864 10.077155 12.735449 11.710505&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;do.call(rpois, list(n = 3, lambda = 2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 2 1 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;so, package up those distribution parameters into a &lt;code&gt;list&lt;/code&gt; first:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;pars &amp;lt;- list(list(n = 6, mean = 10, sd = 3), 
             list(n = 3, lambda = 2))
d &amp;lt;- tibble(dist = dist, pars = pars)
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 2
  dist   pars            
  &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;          
1 &amp;lt;fn&amp;gt;   &amp;lt;named list [3]&amp;gt;
2 &amp;lt;fn&amp;gt;   &amp;lt;named list [2]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;d %&amp;gt;% 
  mutate(z = map2(dist, pars, ~do.call(.x, .y))) %&amp;gt;% 
  unnest(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 9 × 3
  dist   pars                 z
  &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;           &amp;lt;dbl&amp;gt;
1 &amp;lt;fn&amp;gt;   &amp;lt;named list [3]&amp;gt; 10.1 
2 &amp;lt;fn&amp;gt;   &amp;lt;named list [3]&amp;gt; 13.1 
3 &amp;lt;fn&amp;gt;   &amp;lt;named list [3]&amp;gt; 12.4 
4 &amp;lt;fn&amp;gt;   &amp;lt;named list [3]&amp;gt; 14.3 
5 &amp;lt;fn&amp;gt;   &amp;lt;named list [3]&amp;gt;  9.80
6 &amp;lt;fn&amp;gt;   &amp;lt;named list [3]&amp;gt; 13.4 
7 &amp;lt;fn&amp;gt;   &amp;lt;named list [2]&amp;gt;  1   
8 &amp;lt;fn&amp;gt;   &amp;lt;named list [2]&amp;gt;  0   
9 &amp;lt;fn&amp;gt;   &amp;lt;named list [2]&amp;gt;  0   &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;it works!&lt;/p&gt;
&lt;p&gt;And so, we can now make our function:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sample_groups &amp;lt;- function(dist, pars) {
  nr &amp;lt;- length(dist)
  tibble(dist = dist, pars = pars, gp = letters[1:nr]) %&amp;gt;% 
    mutate(z = map2(dist, pars, ~do.call(.x, .y))) %&amp;gt;% 
    unnest(z) %&amp;gt;% 
    select(gp, z)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and to test&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;dists &amp;lt;- c(rnorm, rpois)
pars &amp;lt;- list(list(n = 6, mean = 10, sd = 3), list(n = 3, lambda = 2))
sample_groups(dists, pars)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 9 × 2
  gp        z
  &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
1 a      8.99
2 a     11.2 
3 a     15.5 
4 a     12.4 
5 a     10.3 
6 a     10.6 
7 b      2   
8 b      5   
9 b      2   &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only weirdness is that the user has to specify a list of lists for the parameters (because &lt;code&gt;do.call&lt;/code&gt; needs a list for inputs to its function). But it definitely works.&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;So, for example, if both your sample sizes are the same, you could define eg &lt;code&gt;n &amp;lt;- 10&lt;/code&gt; and it would get expanded to length 2 in the function.&lt;a href="#fnref1" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;It may take a trip to the help files to find out what R calls these parameters.&lt;a href="#fnref2" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5>8db56c03b191bdf514b6d37b8329654a</distill:md5>
      <guid>http://ritsokiguess.site/blogg/posts/2022-05-09-random-sampling-from-groups</guid>
      <pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Why the rank sum test is also a waste of time</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2022-05-06-why-the-rank-sum-test-is-also-a-waste-of-time</link>
      <description>In the same way that the signed rank test is mostly a waste of time, here I argue that the rank sum test is very rarely useful, and offer a less well-known test to use instead.</description>
      <guid>http://ritsokiguess.site/blogg/posts/2022-05-06-why-the-rank-sum-test-is-also-a-waste-of-time</guid>
      <pubDate>Fri, 06 May 2022 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2022-05-06-why-the-rank-sum-test-is-also-a-waste-of-time/why-the-rank-sum-test-is-also-a-waste-of-time_files/figure-html5/unnamed-chunk-12-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Why the signed rank test is a waste of time</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2022-05-04-why-the-signed-rank-test-is-a-waste-of-time</link>
      <description>


&lt;h1 id="packages"&gt;packages&lt;/h1&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="the-one-sample-t-test"&gt;the one-sample t-test&lt;/h1&gt;
&lt;p&gt;Suppose we have one sample of independent, identically distributed observations from some population, and we want to see whether we believe the population mean or median is some value, like 15. The standard test is the one-sample &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test, where here we are pretending that we have a reason to know that the mean is greater than 15 if it is not 15:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;x &amp;lt;- rnorm(n = 10, mean = 16, sd = 3)
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt; [1] 20.86560 13.76096 15.19321 13.90139 16.63971 18.12691 12.76501
 [8] 18.37393 16.01214 19.28764&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;t.test(x, mu = 15, alternative = &amp;quot;greater&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    One Sample t-test

data:  x
t = 1.7818, df = 9, p-value = 0.05423
alternative hypothesis: true mean is greater than 15
95 percent confidence interval:
 14.95704      Inf
sample estimates:
mean of x 
 16.49265 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, the P-value is 0.0542, so we do not quite reject the null hypothesis that the population mean is 15: there is no evidence (at &lt;span class="math inline"&gt;\(\alpha = 0.05\)&lt;/span&gt;) that the population mean is greater than 15. In this case, we have made a type II error, because the population mean is actually 16, and so the null hypothesis is actually wrong but we failed to reject it.&lt;/p&gt;
&lt;p&gt;We use these data again later.&lt;/p&gt;
&lt;p&gt;The theory behind the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test is that the population from which the sample is taken has a normal distribution. This is assessed in practice by looking at a histogram or a normal quantile plot of the data:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(tibble(x), aes(sample = x)) + stat_qq() + stat_qq_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1ec81455b918_files/figure-html/unnamed-chunk-4-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;With a small sample, it is hard to detect whether a deviation from normality like this indicates a non-normal population or is just randomness.&lt;a href="#fn1" class="footnote-ref" id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; In this case, I actually generated my sample from a normal distribution, so I know the answer here is randomness.&lt;/p&gt;
&lt;p&gt;There is another issue here, the Central Limit Theorem. This says, in words, that the sampling distribution of the sample mean from a large sample will be approximately normal, &lt;em&gt;no matter what the population distribution is&lt;/em&gt;. How close the approximation is will depend on how non-normal the population is; if the population is very non-normal (for example, very skewed or has extreme outliers), it might take a very large sample for the approximation to be of any use.&lt;/p&gt;
&lt;p&gt;Example: the chi-squared distribution is right-skewed, with one parameter, the degrees of freedom. As the degrees of freedom increases, the distribution becomes less skewed and more normal in shape.&lt;a href="#fn2" class="footnote-ref" id="fnref2"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Consider the chi-squared distribution with 12 df:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(x = seq(0, 30, 0.1)) %&amp;gt;% 
  mutate(y = dchisq(x, df = 12)) %&amp;gt;% 
  ggplot(aes(x = x, y = y)) + geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1ec81455b918_files/figure-html/unnamed-chunk-5-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;This is mildly skewed. Is a sample of size 20 from this distribution large enough to use the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test? We can simulate the sampling distribution of the sample mean, since we know what the population is, by drawing many (in this case 1000) samples from it and seeing now normal the simulated sample means look:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(sim = 1:1000) %&amp;gt;% 
  rowwise() %&amp;gt;% 
  mutate(my_sample = list(rchisq(n = 20, df = 12))) %&amp;gt;% 
  mutate(my_mean = mean(my_sample)) %&amp;gt;% 
  ggplot(aes(sample = my_mean)) + stat_qq() + stat_qq_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1ec81455b918_files/figure-html/unnamed-chunk-6-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;This is a tiny bit skewed right (the very largest values are slightly too large and the very smallest ones not quite small enough, though the rest of the values hug the line), but I would consider this close enough to trust the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test.&lt;/p&gt;
&lt;p&gt;Now consider the chi-squared distribution with 3 df, which is more skewed:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(x = seq(0, 10, 0.1)) %&amp;gt;% 
  mutate(y = dchisq(x, df = 3)) %&amp;gt;% 
  ggplot(aes(x = x, y = y)) + geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1ec81455b918_files/figure-html/unnamed-chunk-7-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;How normal is the sampling distribution of the sampling mean now, again with a sample of size 20?&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(sim = 1:1000) %&amp;gt;% 
  rowwise() %&amp;gt;% 
  mutate(my_sample = list(rchisq(n = 20, df = 3))) %&amp;gt;% 
  mutate(my_mean = mean(my_sample)) %&amp;gt;% 
  ggplot(aes(sample = my_mean)) + stat_qq() + stat_qq_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1ec81455b918_files/figure-html/unnamed-chunk-8-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;This time, the normal quantile plot definitely strays from the line in a way that indicates a right-skewed non-normal sampling distribution of the sample mean. With this sample size, if the population is as skewed as a chi-squared distribution with 12 degrees of freedom, the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test is fine, but if it is as skewed as a chi-squared distribution with 3 degrees of freedom, the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test is at best questionable.&lt;/p&gt;
&lt;p&gt;So, consideration of whether to use a &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test has two parts: how &lt;em&gt;normal&lt;/em&gt; the population is (answered by asking how normal your &lt;em&gt;sample&lt;/em&gt; is), and how &lt;em&gt;large&lt;/em&gt; the sample is. The larger the sample size is, the less the normality matters, but it is an awkward judgement call to assess whether the non-normality in the data distribution matters enough given the sample size.&lt;a href="#fn3" class="footnote-ref" id="fnref3"&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="the-sign-test"&gt;the sign test&lt;/h1&gt;
&lt;p&gt;If you have decided that your sample does not have close enough to a normal distribution (given the sample size), and therefore that you should not be using the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test, what do you do? Two standard options are the sign test and the signed-rank test, with the latter often being recommended over the former because of the former’s lack of power. These tests are both non-parametric, in that they do not depend on the data having (at least approximately) any specific distribution.&lt;/p&gt;
&lt;p&gt;For the sign test, you count how many of your observations are above and below the null median. Here we use the same data as we used for the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(x) %&amp;gt;% 
  count(x &amp;gt; 15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 2
  `x &amp;gt; 15`     n
  &amp;lt;lgl&amp;gt;    &amp;lt;int&amp;gt;
1 FALSE        3
2 TRUE         7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The number of values (say) above the null median is the test statistic. If the null hypothesis is true, each value is independently either above or below the null median with probability 0.5, and thus the test statistic has a binomial distribution with &lt;span class="math inline"&gt;\(n\)&lt;/span&gt; equal to the sample size and &lt;span class="math inline"&gt;\(p = 0.5\)&lt;/span&gt;. Hence the P-value for an upper-tailed test is&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;sum(dbinom(7:10, size = 10, prob = 0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 0.171875&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The split of 7 values above 15 and 3 below is still fairly close&lt;a href="#fn4" class="footnote-ref" id="fnref4"&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; to 50–50, and so the P-value is large, much larger than for the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test.&lt;/p&gt;
&lt;p&gt;The sign test does not use the data very efficiently: it only counts whether each data value is above or below the hypothesized median. Thus, if you are in a position to use the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test that uses the actual data values, you should do so. However, it is completely assumption-free: as long as the observations really are independent, it does not matter at all what the population distribution looks like.&lt;/p&gt;
&lt;h1 id="the-signed-rank-test"&gt;the signed rank test&lt;/h1&gt;
&lt;p&gt;The signed-rank test occupies a kind of middle ground between the sign test and the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test.&lt;/p&gt;
&lt;p&gt;Here’s how it works for our data, testing for a median of 15, against an upper-tailed alternative:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(x) %&amp;gt;% 
  mutate(diff = x - 15) %&amp;gt;% 
  mutate(abs_diff = abs(diff)) %&amp;gt;% 
  mutate(rk = rank(abs_diff)) -&amp;gt; d
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 10 × 4
       x   diff abs_diff    rk
   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
 1  20.9  5.87     5.87     10
 2  13.8 -1.24     1.24      4
 3  15.2  0.193    0.193     1
 4  13.9 -1.10     1.10      3
 5  16.6  1.64     1.64      5
 6  18.1  3.13     3.13      7
 7  12.8 -2.23     2.23      6
 8  18.4  3.37     3.37      8
 9  16.0  1.01     1.01      2
10  19.3  4.29     4.29      9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Subtract the hypothesized median from each data value, and then rank the differences from smallest to largest in terms of absolute value. The smallest difference in size is 0.193, which gets rank 1, and the largest in size is &lt;span class="math inline"&gt;\(5.87\)&lt;/span&gt;, which gets rank 10. One of the negative differences is &lt;span class="math inline"&gt;\(-2.23\)&lt;/span&gt;, which is the fifth largest in size (has rank 6).&lt;/p&gt;
&lt;p&gt;The next stage is to sum up the ranks separately for the positive and negative differences:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;d %&amp;gt;% group_by(diff &amp;gt; 0) %&amp;gt;% 
  summarize(sum = sum(rk))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 2
  `diff &amp;gt; 0`   sum
  &amp;lt;lgl&amp;gt;      &amp;lt;dbl&amp;gt;
1 FALSE         13
2 TRUE          42&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are only three negative differences, so their ranks add up to only 13, compared to a sum of 42 for the positive differences.&lt;a href="#fn5" class="footnote-ref" id="fnref5"&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; For an upper-tailed test, the test statistic is the sum of the positive differences, which, if &lt;em&gt;large&lt;/em&gt; enough, will lead to rejection of the null hypothesis.&lt;/p&gt;
&lt;p&gt;Is 42 large enough to reject the null with?&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;wilcox.test(x, mu = 15, alternative = &amp;quot;greater&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Wilcoxon signed rank exact test

data:  x
V = 42, p-value = 0.08008
alternative hypothesis: true location is greater than 15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The P-value is 0.0801, not small enough to reject the null median of 15 in favour of a larger value. It is a little bigger than for the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test, but smaller than for the sign test.&lt;/p&gt;
&lt;p&gt;A historical note: the name usually attached to the signed-rank test is &lt;a href="https://en.wikipedia.org/wiki/Frank_Wilcoxon"&gt;Frank Wilcoxon&lt;/a&gt;. He worked out the null distribution of the signed rank statistic (an exercise in combinatorics).&lt;/p&gt;
&lt;p&gt;The R function is a bit of a confusing misnomer, because there was also a statistician called &lt;a href="https://en.wikipedia.org/wiki/Walter_Francis_Willcox"&gt;Walter Francis Willcox&lt;/a&gt;, who had nothing to do with this test.&lt;/p&gt;
&lt;h2 id="assessing-the-signed-rank-test"&gt;assessing the signed rank test&lt;/h2&gt;
&lt;p&gt;The signed-rank test seemed to behave well enough in our example, with actually normal data. But the point of mentioning the test is as something to use when the data are &lt;em&gt;not&lt;/em&gt; normal.&lt;/p&gt;
&lt;p&gt;So let’s take some samples from our skewed chi-squared distribution with 3 df.&lt;/p&gt;
&lt;p&gt;This distribution has this median:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;med &amp;lt;- qchisq(0.5, 3)
med&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 2.365974&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and away we go. I’ll do 10,000 simulations this time:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(sim=1:10000) %&amp;gt;% 
  rowwise() %&amp;gt;% 
  mutate(my_sample = list(rchisq(10, 3))) %&amp;gt;% 
  mutate(my_test = list(wilcox.test(my_sample, mu = med, alternative = &amp;quot;greater&amp;quot;))) %&amp;gt;% 
  mutate(my_p = my_test$p.value) -&amp;gt; dd
dd&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 10,000 × 4
# Rowwise: 
     sim my_sample  my_test   my_p
   &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;     &amp;lt;list&amp;gt;   &amp;lt;dbl&amp;gt;
 1     1 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.862 
 2     2 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.722 
 3     3 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.5   
 4     4 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.615 
 5     5 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.0322
 6     6 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.947 
 7     7 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.0322
 8     8 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.0244
 9     9 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.0967
10    10 &amp;lt;dbl [10]&amp;gt; &amp;lt;htest&amp;gt; 0.539 
# … with 9,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since the null hypothesis is true, the P-values should have a uniform distribution:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(dd, aes(x = my_p)) + geom_histogram(bins = 12)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file1ec81455b918_files/figure-html/unnamed-chunk-16-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;That doesn’t look very uniform, but rather skewed to the right, with too many low values, so that the test rejects more often than it should:&lt;a href="#fn6" class="footnote-ref" id="fnref6"&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;dd %&amp;gt;% count(my_p &amp;lt;= 0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 2
# Rowwise: 
  `my_p &amp;lt;= 0.05`     n
  &amp;lt;lgl&amp;gt;          &amp;lt;int&amp;gt;
1 FALSE           9194
2 TRUE             806&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A supposed test at &lt;span class="math inline"&gt;\(\alpha = 0.05\)&lt;/span&gt; actually has a probability near 0.08 of making a type I error. (That’s why I did 10,000 simulations, in the hopes of eliminating sampling variability as a reason for it being different than 0.05.)&lt;/p&gt;
&lt;p&gt;To investigate what happened, let’s look at one random sample and see whether we can reason it out:&lt;a href="#fn7" class="footnote-ref" id="fnref7"&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;set.seed(457297)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;x &amp;lt;- rchisq(10, 3)
x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt; [1] 5.6369920 7.8136036 2.8290842 8.2463800 0.6228536 0.8004611
 [7] 2.2627925 6.3275717 1.2881783 0.6634575&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and go through the calculations for the signed rank statistic again:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tibble(x) %&amp;gt;% 
  mutate(diff = x - med) %&amp;gt;% 
  mutate(abs_diff = abs(diff)) %&amp;gt;% 
  mutate(rk = rank(abs_diff)) -&amp;gt; d
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 10 × 4
       x   diff abs_diff    rk
   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
 1 5.64   3.27     3.27      7
 2 7.81   5.45     5.45      9
 3 2.83   0.463    0.463     2
 4 8.25   5.88     5.88     10
 5 0.623 -1.74     1.74      6
 6 0.800 -1.57     1.57      4
 7 2.26  -0.103    0.103     1
 8 6.33   3.96     3.96      8
 9 1.29  -1.08     1.08      3
10 0.663 -1.70     1.70      5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are five positive and five negative differences, exactly as we would expect. But the positive differences are the &lt;em&gt;four largest ones in size&lt;/em&gt;, so that the sum of the ranks for the positive differences is quite a bit larger than the sum of the ranks for the negative differences: 36 as against 19:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;d %&amp;gt;% 
  group_by(diff &amp;gt; 0) %&amp;gt;% 
  summarize(sum = sum(rk))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 2
  `diff &amp;gt; 0`   sum
  &amp;lt;lgl&amp;gt;      &amp;lt;dbl&amp;gt;
1 FALSE         19
2 TRUE          36&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This seems like a bit of a difference in rank sums, given that the null hypothesis is actually &lt;em&gt;true&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Why did this happen, and why might it happen again? The population distribution is skewed to the right, so that there will occasionally be sample values &lt;em&gt;much&lt;/em&gt; larger than the null median (even if that median is correct). There can not be sample values much &lt;em&gt;smaller&lt;/em&gt; than the null median, because the distribution is bunched up at the bottom. That means that the positive differences will tend to be the largest ones in size, and hence the test statistic will tend to be bigger, and the P-value smaller, than ought to be the case.&lt;/p&gt;
&lt;h1 id="conclusions"&gt;conclusions&lt;/h1&gt;
&lt;p&gt;The usual get-out for the above is to say that the signed-rank test only applies to symmetric distributions. Except that, one of the principal ways that the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test can fail is that the population distribution is skewed, and what we are then saying is that in that situation, we cannot use the signed-rank test either. Really, the only situation in which the signed-rank test has any value is when the population is symmetric with long tails or outliers, which seems to me a small fraction of the times when you would not want to use a &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test.&lt;/p&gt;
&lt;p&gt;So, the official recommendation is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;when the population distribution seems normal enough (given the sample size), use the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test&lt;/li&gt;
&lt;li&gt;when the population distribution is not normal enough but is apparently symmetric, use the signed-rank test&lt;/li&gt;
&lt;li&gt;otherwise, use the sign test.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second of those seems a bit unlikely (or unlikely to be sure enough about in practice), so that when I teach this stuff, it’s the &lt;span class="math inline"&gt;\(t\)&lt;/span&gt;-test or the sign test. As I have explained, the signed-rank test is only very rarely useful, and therefore, I contend, it is a waste of time to learn about it.&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div class="footnotes"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;This is a good place to use Di Cook’s idea of a “line-up”, where you generate eight normal quantile plots of actual normal data, and then add your actual normal quantile plot, shuffle them around, and see whether you can pick which one is your data. If you can, your data is different from what random normals would produce.&lt;a href="#fnref1" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn2"&gt;&lt;p&gt;In the limit as degrees of freedom increases, the distribution &lt;em&gt;is&lt;/em&gt; normal.&lt;a href="#fnref2" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn3"&gt;&lt;p&gt;When you have actual data from some unknown distribution, one way to get a sense of the sampling distribution of the sample mean is to use the bootstrap: generate a large number of samples &lt;em&gt;from the sample&lt;/em&gt; with replacement, work out the mean of each one, and then see whether that distribution of sample means is close to normal. This is still a subjective call, but at least it is only one thing to assess, rather than having to combine an assessment of normality with an assessment of sample size.&lt;a href="#fnref3" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn4"&gt;&lt;p&gt;In the sense that if you tossed a fair coin 10 times, you would not be terribly surprised to see 7 heads and 3 tails.&lt;a href="#fnref4" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn5"&gt;&lt;p&gt;The three negative differences average to a rank of about 4.3, while the seven positive differences average to a rank of 6. Thus the positive differences are typically bigger in size than the negative ones are.&lt;a href="#fnref5" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn6"&gt;&lt;p&gt;A 95% confidence interval for the true type I error probability is from 0.075 to 0.086, so it is definitely higher than 0.05. &lt;code&gt;prop.test&lt;/code&gt; is a nice way to get this interval.&lt;a href="#fnref6" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id="fn7"&gt;&lt;p&gt;I am cheating and using one that I think makes the point clear.&lt;a href="#fnref7" class="footnote-back"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5>2a23cdd6dde279ef12f465e4355b3fd0</distill:md5>
      <guid>http://ritsokiguess.site/blogg/posts/2022-05-04-why-the-signed-rank-test-is-a-waste-of-time</guid>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2022-05-04-why-the-signed-rank-test-is-a-waste-of-time/why-the-signed-rank-test-is-a-waste-of-time_files/figure-html5/unnamed-chunk-4-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Kommentar</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-12-04-kommentar</link>
      <description>Or, Comments, in other words.</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-12-04-kommentar</guid>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Tidy simulation</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-14-tidy-simulation</link>
      <description>Using rowwise to save calculation, estimate power or test size, bootstrap distributions</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-14-tidy-simulation</guid>
      <pubDate>Fri, 26 Nov 2021 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2021-11-14-tidy-simulation/tidy-simulation_files/figure-html5/unnamed-chunk-15-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Welcome</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-07-welcome</link>
      <description>The new home of my blog</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-07-welcome</guid>
      <pubDate>Sun, 07 Nov 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Density plots</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-07-density-plots</link>
      <description>An alternative to histograms and boxplots</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-07-density-plots</guid>
      <pubDate>Sat, 16 Oct 2021 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2021-11-07-density-plots/density-plots_files/figure-html5/unnamed-chunk-12-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Correcting a dataframe</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-07-correcting-a-dataframe</link>
      <description>The tidyverse way.</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-07-correcting-a-dataframe</guid>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Sampling locations in a city</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-07-sampling-locations-in-a-city</link>
      <description>with the aim of getting an aerial map of that location.</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-07-sampling-locations-in-a-city</guid>
      <pubDate>Sat, 10 Oct 2020 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2021-11-07-sampling-locations-in-a-city/Screenshot_2020-10-10_12-40-39.png" medium="image" type="image/png" width="617" height="431"/>
    </item>
    <item>
      <title>Another tidying problem</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2020-07-09-another-tidying-problem</link>
      <description>that ends up with a matched pairs test after tidying.</description>
      <guid>http://ritsokiguess.site/blogg/posts/2020-07-09-another-tidying-problem</guid>
      <pubDate>Thu, 09 Jul 2020 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2020-07-09-another-tidying-problem/another-tidying-problem_files/figure-html5/unnamed-chunk-12-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Understanding the result of a chi-square test</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2020-03-14-understanding-the-result-of-a-chi-square-test</link>
      <description>Going beyond the chi-square statistic and its P-value</description>
      <guid>http://ritsokiguess.site/blogg/posts/2020-03-14-understanding-the-result-of-a-chi-square-test</guid>
      <pubDate>Sat, 14 Mar 2020 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Two header rows and other spreadsheets</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-08-two-header-rows-and-other-spreadsheets</link>
      <description>Tidying data arranged in odd ways</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-08-two-header-rows-and-other-spreadsheets</guid>
      <pubDate>Sun, 01 Dec 2019 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2021-11-08-two-header-rows-and-other-spreadsheets/two-header-rows-and-other-spreadsheets_files/figure-html5/unnamed-chunk-9-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Un-counting</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2019-07-13-un-counting</link>
      <description>Why you would want to do the opposite of counting</description>
      <guid>http://ritsokiguess.site/blogg/posts/2019-07-13-un-counting</guid>
      <pubDate>Sat, 13 Jul 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Some things I learned today</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-12-some-things-i-learned-today</link>
      <description>Stan files; R Markdown figures in LaTeX; Beamer in R Markdown; Build All and makefiles</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-12-some-things-i-learned-today</guid>
      <pubDate>Wed, 22 May 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Changing a lot of things in a lot of places</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-19-changing-a-lot-of-things-in-a-lot-of-places</link>
      <description>Making a lot of changes in text, all in one go</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-19-changing-a-lot-of-things-in-a-lot-of-places</guid>
      <pubDate>Sun, 12 May 2019 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Distance between clusters</title>
      <dc:creator>Ken Butler</dc:creator>
      <link>http://ritsokiguess.site/blogg/posts/2021-11-19-distance-between-clusters</link>
      <description>How far apart are two *clusters* of objects, when all I have are distances between objects?</description>
      <guid>http://ritsokiguess.site/blogg/posts/2021-11-19-distance-between-clusters</guid>
      <pubDate>Tue, 23 Apr 2019 00:00:00 +0000</pubDate>
      <media:content url="http://ritsokiguess.site/blogg/posts/2021-11-19-distance-between-clusters/distance-between-clusters_files/figure-html5/unnamed-chunk-2-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
  </channel>
</rss>
